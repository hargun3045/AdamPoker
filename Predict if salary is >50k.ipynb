{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use this\n",
    "\n",
    "Run each cell from top to bottom. \n",
    "View README.md for more infos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init global infos\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokerdf = pd.read_csv('train.csv',index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokercols = pokerdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a new input for my Adam Poker application\n",
    "inputs = ( \n",
    "    (\"S1\", ('1','2','3','4')), \n",
    "    (\"C1\", (\"continuous\",)), \n",
    "    (\"S2\", ('1','2','3','4')), \n",
    "    (\"C2\", (\"continuous\",)), \n",
    "    (\"S3\", ('1','2','3','4')), \n",
    "    (\"C3\", (\"continuous\",)), \n",
    "    (\"S4\", ('1','2','3','4')), \n",
    "    (\"C4\", (\"continuous\",)), \n",
    "    (\"S5\", ('1','2','3','4')), \n",
    "    (\"C5\", (\"continuous\",)), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: [4, 1, 4, 1, 4, 1, 4, 1, 4, 1]\n",
      "input_dim: 25\n"
     ]
    }
   ],
   "source": [
    "input_shape = []\n",
    "for i in inputs:\n",
    "    count = len(i[1 ])\n",
    "    input_shape.append(count)\n",
    "input_dim = sum(input_shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(\"input_dim:\", input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dim: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = tuple(range(0,10))  # (\">50K\", \"<=50K\")\n",
    "output_dim = len(outputs)\n",
    "print(\"output_dim:\", output_dim)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function 2    \n",
    "    \n",
    "def find_means_for_continuous_types(X):\n",
    "    means = []\n",
    "    for col in range(len(X[0])):\n",
    "        summ = 0\n",
    "        count = 0.000000000000000000001\n",
    "        for value in X[:, col]:\n",
    "            if isinstance(value,float): \n",
    "                summ += value\n",
    "                count +=1\n",
    "        means.append(summ/count)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dtype to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokerdf[['C1','C2','C3','C4','C5']] = pokerdf[['C1','C2','C3','C4','C5']].astype('float64')\n",
    "pokerdf[['S1','S2','S3','S4','S5']] = pokerdf[['S1','S2','S3','S4','S5']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function 3\n",
    "def prepare_data(raw_data, means):\n",
    "    \n",
    "    X = raw_data[:, :-1]\n",
    "    y = raw_data[:, -1:]\n",
    "    \n",
    "    # X:\n",
    "    def flatten_persons_inputs_for_model(person_inputs):\n",
    "        global inputs\n",
    "        global input_shape\n",
    "        global input_dim\n",
    "        global means\n",
    "        float_inputs = []\n",
    "\n",
    "        for i in range(len(input_shape)):\n",
    "            features_of_this_type = input_shape[i]\n",
    "            is_feature_continuous = features_of_this_type == 1\n",
    "\n",
    "            if is_feature_continuous:\n",
    "                mean = means[i]\n",
    "                scale_factor = 1/(2*mean)\n",
    "                float_inputs.append(person_inputs[i]*scale_factor)\n",
    "#                 if isinstance(person_inputs[i],float):\n",
    "#                     scale_factor = 1/(2*mean)  # we prefer inputs mainly scaled from -1 to 1. \n",
    "#                     float_inputs.append(float(person_inputs[i])*scale_factor)\n",
    "#                 else:\n",
    "#                     float_inputs.append(mean)\n",
    "            else:\n",
    "                for j in range(features_of_this_type):\n",
    "                    feature_name = inputs[i][1][j]\n",
    "\n",
    "                    if feature_name == person_inputs[i]:\n",
    "                        float_inputs.append(1.)\n",
    "                    else:\n",
    "                        float_inputs.append(0)\n",
    "        return float_inputs\n",
    "    \n",
    "    new_X = []\n",
    "    for person in range(len(X)):\n",
    "        formatted_X = flatten_persons_inputs_for_model(X[person])\n",
    "        new_X.append(formatted_X)\n",
    "    new_X = np.array(new_X)\n",
    "    \n",
    "    # y:\n",
    "    new_y = to_categorical(y, num_classes = 10)\n",
    "    \n",
    "#     new_y = []\n",
    "#     for i in range(len(y)):\n",
    "#         if y[i] == \">50k\":\n",
    "#             new_y.append((1, 0))\n",
    "#         else:  # y[i] == \"<=50k\":\n",
    "#             new_y.append((0, 1))\n",
    "#     new_y = np.array(new_y)\n",
    "    \n",
    "    return (new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding means for poker data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartrain = pokerdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values for data types (if continuous): [0.0, 6.995241903238704, 0.0, 7.014194322271091, 0.0, 7.014154338264694, 0.0, 6.9424630147940825, 0.0, 6.962734906037585, 0.0]\n"
     ]
    }
   ],
   "source": [
    "means = find_means_for_continuous_types(hartrain)\n",
    "print(\"Mean values for data types (if continuous):\", means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(hartrain, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data format example:\n",
      "[1.         0.         0.         0.         0.57181725 0.\n",
      " 1.         0.         0.         0.2851361  0.         1.\n",
      " 0.         0.         0.78412874 0.         1.         0.\n",
      " 0.         0.1440411  0.         1.         0.         0.\n",
      " 0.07181086]\n"
     ]
    }
   ],
   "source": [
    "# Explanation on data format\n",
    "print(\"Training data format example:\")\n",
    "print(X_train[4])  # 4 is a random person, from cuba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "mid_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(mid_dim, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='relu'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics = ['accuracy'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               2600      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 3,610\n",
      "Trainable params: 3,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training_datas, dimension): (25010, 25)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "print(\"(training_datas, dimension):\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4185 - accuracy: 0.4485 - val_loss: 1.7236 - val_accuracy: 0.0084\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4816 - accuracy: 0.2416 - val_loss: 1.3722 - val_accuracy: 0.4742\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.2155 - accuracy: 0.4923 - val_loss: 1.1396 - val_accuracy: 0.4984\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.4966 - val_loss: 1.0703 - val_accuracy: 0.4994\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.0670 - accuracy: 0.4963 - val_loss: 1.0622 - val_accuracy: 0.5050\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4162 - accuracy: 0.1908 - val_loss: 1.5627 - val_accuracy: 0.0178\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4909 - accuracy: 0.0214 - val_loss: 1.4435 - val_accuracy: 0.0196\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.3878 - accuracy: 0.1630 - val_loss: 1.3506 - val_accuracy: 0.3978\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.3021 - accuracy: 0.4769 - val_loss: 1.2828 - val_accuracy: 0.5094\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.2234 - accuracy: 0.4971 - val_loss: 1.1932 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e8ed190>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(new_X_train, y_train, nb_epoch=3, batch_size=16, show_accuracy=True, verbose=2)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
