{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/poker/bin/python'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use this\n",
    "\n",
    "Run each cell from top to bottom. \n",
    "View README.md for more infos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init global infos\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokerdf = pd.read_csv('train.csv',index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokercols = pokerdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a new input for my Adam Poker application\n",
    "inputs = ( \n",
    "    (\"S1\", ('1','2','3','4')), \n",
    "    (\"C1\", (\"continuous\",)), \n",
    "    (\"S2\", ('1','2','3','4')), \n",
    "    (\"C2\", (\"continuous\",)), \n",
    "    (\"S3\", ('1','2','3','4')), \n",
    "    (\"C3\", (\"continuous\",)), \n",
    "    (\"S4\", ('1','2','3','4')), \n",
    "    (\"C4\", (\"continuous\",)), \n",
    "    (\"S5\", ('1','2','3','4')), \n",
    "    (\"C5\", (\"continuous\",)), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: [4, 1, 4, 1, 4, 1, 4, 1, 4, 1]\n",
      "input_dim: 25\n"
     ]
    }
   ],
   "source": [
    "input_shape = []\n",
    "for i in inputs:\n",
    "    count = len(i[1 ])\n",
    "    input_shape.append(count)\n",
    "input_dim = sum(input_shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(\"input_dim:\", input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dim: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = tuple(range(0,10))  # (\">50K\", \"<=50K\")\n",
    "output_dim = len(outputs)\n",
    "print(\"output_dim:\", output_dim)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function 2    \n",
    "    \n",
    "def find_means_for_continuous_types(X):\n",
    "    means = []\n",
    "    for col in range(len(X[0])):\n",
    "        summ = 0\n",
    "        count = 0.000000000000000000001\n",
    "        for value in X[:, col]:\n",
    "            if isinstance(value,float): \n",
    "                summ += value\n",
    "                count +=1\n",
    "        means.append(summ/count)\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dtype to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokerdf[['C1','C2','C3','C4','C5']] = pokerdf[['C1','C2','C3','C4','C5']].astype('float64')\n",
    "pokerdf[['S1','S2','S3','S4','S5']] = pokerdf[['S1','S2','S3','S4','S5']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful function 3\n",
    "def prepare_data(raw_data, means):\n",
    "    \n",
    "    X = raw_data[:, :-1]\n",
    "    y = raw_data[:, -1:]\n",
    "    \n",
    "    # X:\n",
    "    def flatten_persons_inputs_for_model(person_inputs):\n",
    "        global inputs\n",
    "        global input_shape\n",
    "        global input_dim\n",
    "        global means\n",
    "        float_inputs = []\n",
    "\n",
    "        for i in range(len(input_shape)):\n",
    "            features_of_this_type = input_shape[i]\n",
    "            is_feature_continuous = features_of_this_type == 1\n",
    "\n",
    "            if is_feature_continuous:\n",
    "                mean = means[i]\n",
    "                scale_factor = 1/(2*mean)\n",
    "                float_inputs.append(person_inputs[i]*scale_factor)\n",
    "#                 if isinstance(person_inputs[i],float):\n",
    "#                     scale_factor = 1/(2*mean)  # we prefer inputs mainly scaled from -1 to 1. \n",
    "#                     float_inputs.append(float(person_inputs[i])*scale_factor)\n",
    "#                 else:\n",
    "#                     float_inputs.append(mean)\n",
    "            else:\n",
    "                for j in range(features_of_this_type):\n",
    "                    feature_name = inputs[i][1][j]\n",
    "\n",
    "                    if feature_name == person_inputs[i]:\n",
    "                        float_inputs.append(1.)\n",
    "                    else:\n",
    "                        float_inputs.append(0)\n",
    "        return float_inputs\n",
    "    \n",
    "    new_X = []\n",
    "    for person in range(len(X)):\n",
    "        formatted_X = flatten_persons_inputs_for_model(X[person])\n",
    "        new_X.append(formatted_X)\n",
    "    new_X = np.array(new_X)\n",
    "    \n",
    "    # y:\n",
    "    new_y = to_categorical(y, num_classes = 10)\n",
    "    \n",
    "#     new_y = []\n",
    "#     for i in range(len(y)):\n",
    "#         if y[i] == \">50k\":\n",
    "#             new_y.append((1, 0))\n",
    "#         else:  # y[i] == \"<=50k\":\n",
    "#             new_y.append((0, 1))\n",
    "#     new_y = np.array(new_y)\n",
    "    \n",
    "    return (new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding means for poker data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartrain = pokerdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values for data types (if continuous): [0.0, 6.995241903238704, 0.0, 7.014194322271091, 0.0, 7.014154338264694, 0.0, 6.9424630147940825, 0.0, 6.962734906037585, 0.0]\n"
     ]
    }
   ],
   "source": [
    "means = find_means_for_continuous_types(hartrain)\n",
    "print(\"Mean values for data types (if continuous):\", means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(hartrain, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data format example:\n",
      "[1.         0.         0.         0.         0.57181725 0.\n",
      " 1.         0.         0.         0.2851361  0.         1.\n",
      " 0.         0.         0.78412874 0.         1.         0.\n",
      " 0.         0.1440411  0.         1.         0.         0.\n",
      " 0.07181086]\n"
     ]
    }
   ],
   "source": [
    "# Explanation on data format\n",
    "print(\"Training data format example:\")\n",
    "print(X_train[4])  # 4 is a random person, from cuba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Init model\n",
    "\n",
    "mid_dim = 2000\n",
    "\n",
    "sec_dim = 1000\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(mid_dim, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(sec_dim, activation='relu'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = ['accuracy'] )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 2000)              52000     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 2,063,010\n",
      "Trainable params: 2,063,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(training_datas, dimension): (25010, 25)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "print(\"(training_datas, dimension):\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0095 - accuracy: 0.4842 - val_loss: 0.9842 - val_accuracy: 0.4856\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9713 - accuracy: 0.5024 - val_loss: 0.9665 - val_accuracy: 0.5248\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9502 - accuracy: 0.5177 - val_loss: 0.9565 - val_accuracy: 0.5282\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9347 - accuracy: 0.5384 - val_loss: 0.9587 - val_accuracy: 0.5184\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9272 - accuracy: 0.5405 - val_loss: 0.9562 - val_accuracy: 0.5444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4d1c437310>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(new_X_train, y_train, nb_epoch=3, batch_size=16, show_accuracy=True, verbose=2)\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New stuff here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# This is a sample of a scheduler I used in the past\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.85\n",
    "    decay_step = 1\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * pow(decay_rate, np.floor(epoch / decay_step))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [LearningRateScheduler(lr_scheduler, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CategoricalCrossentropy(label_smoothing=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 100)               2600      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 10,710\n",
      "Trainable params: 10,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mid_dim = 100\n",
    "\n",
    "sec_dim = 50\n",
    "\n",
    "third_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(mid_dim, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(sec_dim, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(third_dim, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "model.compile(loss=loss, optimizer='Adam',metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4765 - accuracy: 0.5527 - val_loss: 1.4935 - val_accuracy: 0.5358\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4740 - accuracy: 0.5561 - val_loss: 1.4866 - val_accuracy: 0.5456\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4718 - accuracy: 0.5615 - val_loss: 1.4942 - val_accuracy: 0.5248\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4687 - accuracy: 0.5631 - val_loss: 1.4918 - val_accuracy: 0.5282\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4662 - accuracy: 0.5642 - val_loss: 1.4935 - val_accuracy: 0.5216\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4647 - accuracy: 0.5675 - val_loss: 1.4908 - val_accuracy: 0.5332\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4613 - accuracy: 0.5701 - val_loss: 1.4926 - val_accuracy: 0.5380\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4603 - accuracy: 0.5730 - val_loss: 1.4918 - val_accuracy: 0.5394\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4566 - accuracy: 0.5750 - val_loss: 1.4945 - val_accuracy: 0.5370\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4548 - accuracy: 0.5778 - val_loss: 1.4937 - val_accuracy: 0.5402\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4522 - accuracy: 0.5827 - val_loss: 1.4976 - val_accuracy: 0.5302\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4512 - accuracy: 0.5821 - val_loss: 1.4961 - val_accuracy: 0.5338\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4493 - accuracy: 0.5821 - val_loss: 1.4985 - val_accuracy: 0.5228\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4469 - accuracy: 0.5860 - val_loss: 1.5031 - val_accuracy: 0.5308\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4445 - accuracy: 0.5894 - val_loss: 1.5045 - val_accuracy: 0.5162\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4431 - accuracy: 0.5921 - val_loss: 1.5052 - val_accuracy: 0.5120\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4401 - accuracy: 0.5925 - val_loss: 1.5082 - val_accuracy: 0.5120\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4387 - accuracy: 0.5929 - val_loss: 1.5109 - val_accuracy: 0.5250\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4364 - accuracy: 0.5940 - val_loss: 1.5123 - val_accuracy: 0.5172\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4353 - accuracy: 0.5978 - val_loss: 1.5150 - val_accuracy: 0.5194\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4336 - accuracy: 0.6008 - val_loss: 1.5094 - val_accuracy: 0.5196\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4315 - accuracy: 0.6000 - val_loss: 1.5129 - val_accuracy: 0.5194\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4301 - accuracy: 0.6011 - val_loss: 1.5162 - val_accuracy: 0.5166\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4284 - accuracy: 0.6069 - val_loss: 1.5181 - val_accuracy: 0.5250\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4269 - accuracy: 0.6069 - val_loss: 1.5191 - val_accuracy: 0.5216\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4245 - accuracy: 0.6103 - val_loss: 1.5238 - val_accuracy: 0.5144\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4215 - accuracy: 0.6152 - val_loss: 1.5268 - val_accuracy: 0.5200\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4191 - accuracy: 0.6150 - val_loss: 1.5228 - val_accuracy: 0.5188\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4193 - accuracy: 0.6122 - val_loss: 1.5282 - val_accuracy: 0.5174\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.4170 - accuracy: 0.6176 - val_loss: 1.5224 - val_accuracy: 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4880d28ed0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=30, validation_split=0.2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('test.csv',index_col = False); del testdf['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf[['C1','C2','C3','C4','C5']] = testdf[['C1','C2','C3','C4','C5']].astype('float64')\n",
    "testdf[['S1','S2','S3','S4','S5']] = testdf[['S1','S2','S3','S4','S5']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "hartest = testdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['ycol'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,_ = prepare_data(hartest,means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 25)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.        , 0.        , 0.71477156,\n",
       "       0.        , 1.        , 0.        , 0.        , 0.14256805,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.21385329,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.57616439,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.07181086])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = pd.Series(hands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549271\n",
       "1    423383\n",
       "2     16914\n",
       "3      8155\n",
       "5      1944\n",
       "4       286\n",
       "6        20\n",
       "9        14\n",
       "8         7\n",
       "7         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hands.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sampleSubmission.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.hand = hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('baselineMLP.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poker",
   "language": "python",
   "name": "poker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
